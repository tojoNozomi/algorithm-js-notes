# 算法与数据结构学习（JavaScript）

## 基础数据结构

### 栈 （Stack）

[栈的代码实现](./src/stack/index.js)

* 栈是一种遵循“后进先出（LIFO Last In First Out）”的序列，即最后入栈的元素会最先被取出来
* 栈的大小（size） 指的是数组含有的元素的数量（数组的长度）
* 栈的实现以及相关的方法



### 队列 （Queue）

[队列的代码实现](./src/queue/index.js)

* 队列是一种遵循“先进先出（FIFO First In First Out）”原则的序列，先进入队列的元素会被先取出来
* 除了出入顺序不一样之外，其他的都和栈一样


##### 如果考虑优先级呢

[优先队列的代码实现](./src/queue/PriorityQueue.js)

* 实际上在生活中的队列不止这么简单，比如附带优先级的情况下

* 队列是这样作优先级判断的：在进入队列的时候比较优先级，然后插入到队列中的位置；或者是在出队列的时候，在队列中按照优先级选取
* 而实际上，从结果来看的话，两种优先队列在最终表现上基本是一致的，这里选取进入队列时进行优先级比较，出列时使用默认的出列方法

##### 另外一种队列的变形

* 循环队列： 元素出队列之后，再次进入到队尾 (待补充代码)

### 链表 （Linked list）

[链表的代码实现](./src/LinkedList/index.js)

* 背景： 因为很多时候数组的大小是固定的（比如C++这些语言），而且从数组起点和中间插入或者移除的成本会比较高。

* 于是乎就有了链表这种数据结构，与数组不同的是，链表中的元素并不是连续的，每个元素之间都由一个存储元素本身的节点和一个指向下一个元素的引用（也称指针，或者链接）组成

* 好处： 和数组一样是能存储有序的元素集合，不过添加或移动元素时不需要移动其他元素。另外需要访问一个元素时得从头开始遍历列表直到找到所需要的元素


##### 其他种类的链表
* 双向链表： 在单向链表的基础上，即节点除了存储元素本身和下一个元素的引用之外，还存储着上一个元素的引用

* 循环链表： 链表的最后一个节点的下一个元素的引用指向第一个节点


### 集合 （Set） 
* 集合是无序且唯一的元素组成的（有限集合，数学上的概念）
* 空集： 没有元素的集合 
* 一些集合的操作： 并集、交集、差集、子集



### 字典 （Dictionary）
* 字典是一种以键值对[key, value]的形式存储数据的数据结构
* 与集合类似，集合是[value, value]的形式存储的，字典是[key, value]，字典也称作映射
* 例子： 实际意义上的字典、电话簿


### 散列表（Hash Table）
* 基于字典表的一种散列实现
* 作用： 尽可能快地在数据结构中找到目标值
* 最常见的一种散列函数“lose lose”： 简单地将键名中的每个字母的ASCII码相加

* 需要实现一个散列函数，用于键名到hash值的映射。在“lose lose”算法中，为了能够获得比较小的数，可以将相加的结果与任意一个数字作取模运算（mod， %）
* 数据结构中，table 可以看作是一个length无限长的数组（JS的特性让定义这个很简单）
* 因为直接通过键名到key（hash值）的映射，可以实现快速取值【参考后面的搜索算法】

##### 散列集合
* 由一个集合构成，但是插入、移除或者取出的时候，使用散列函数，只存储唯一的不重复的值
* 与散列表不同的是，只插入值而没有键

##### 解决冲突
* 实际上在使用的时候，会遇到刚好两个键名映射出来的hash值是一样的，这种情况下需要用一些方法来避免冲突
* 方法1: 分离链接
* 也就是在散列表的结构中，使用链表来存储键值，不过相比普通的散列表需要更多的空间来存储。
* 修改put方法： 先判断目标hash是否已经由链表存在，有的话就直接在链表进行add操作，没有的话就创建一个链表再add进去
* 修改add方法： 判断是否为空，空则返回undefined；非空，则遍历链表，比对键名并返回结果

* 方法2: 线性探查
* 当向相同的位置插入一个新元素时，若索引为index的地方（hash值为index）已经被占用了，则尝试插入index+1位置，若也被占用了，则接着尝试index+2，以此类推
* 修改put方法： 若被占用时，则使用while条件判断，一直遍历下去
* 修改get方法： 和put类似，先hash计算后在指定位置上：1、检查是否存在元素，若无则返回undefined
2、若存在元素，则判断键名是否相等；若不相等的话，则hash值+1，再判断是否存在或者是否键名相等
3、返回键名相等的元素
* 修改remove方法： 与get类似，只不过在键名相等时的操作从返回变成设置为undefined（还要返回操作是否成功）

* 更好的散列函数djb2散列函数（比较受推荐的一种算法）


### 树（Tree）
* 树是一种非顺序的数据结构。对于存储需要快熟查找的数据非常有用
* 常见例子： 家族谱、公司的组织架构图
* 一个树结构，包含着一系列存在父子关系的节点，每个节点都有父节点（根节点除外）和0到多个子节点的引用
* 至少有一个子节点的节点被称为内部节点
* 没有子节点的节点则被称为外部节点或叶子节点
* 节点可以有祖先和后代
* 祖先： 父节点、祖父节点、曾祖父节点
* 后代： 子节点、孙子节点、曾孙节点
* 子树： （由当前节点以及其后代组成）
* 深度： 取决于节点的祖先节点的数量（直系）

##### 二叉搜索树（BST： Binary Search Tree）
* 特性：二叉树的子节点最多只有两个（左侧节点和右侧节点）。
* 二叉搜索树： 只允许左侧节点的值小于父节点，而右侧节点的值要大于父节点
* 在代码实现中通过指针来表示节点之间的关系（术语中称为边），而节点本身在树相关的术语中称为键 Key
* insert方法的实现：
1、创建Node类的实例 2、判断根节点是否为空，是则root被赋值（用刚创建的节点），结束
3、若根节点存在，则判断当前节点和根节点的大小，若小的话往左边遍历，若大的话则往右边遍历
4、在上述情况中，如果当前节点的左/右节点指针为空时，恰好新节点比当前节点小/大时，则直接插入

##### BST的三种遍历
* 中序遍历： 以从最小到最大的顺序访问所有节点（先访问左节点，再访问自身，最后访问右节点）
* 应用：对树中的元素进行排序
* 利用递归的先后执行顺序的区别来实现（同步代码）

* 先序遍历： 优先于后代访问的顺序（先访问本节点，再访问左节点，最后访问右节点）
* 后序遍历： 优先访问后代节点（先访问左节点，再访问右节点，最后访问自身）
* 先中后 三种遍历顺序实际上就是访问本节点的先后顺序（无论怎么排左节点都是优先于右节点访问的）

* BST中的值： 最小值（一直访问右节点，直到所访问的节点是叶子节点时的值） 
最大值（一直访问右节点，直到所访问的节点是叶子节点时的值）
* 特定值（的搜索）： 判断目标值和当前节点的大小，如果小于当前节点的键，则往右；如果大于当前节点的键，则往左。迭代下去，直到目标值和当前节点的键相等，返回true。若不出现相等的情况则返回false
* 移除节点： 基于search的方法，在找到目标值之后，若该节点是叶子节点，则另node为null；若只有一个子节点的情况下，则令子节点替换该节点；若有两个子节点，则先找出右边子树的最小节点，来替换目标节点，并从原位置移除，最后向父节点返回更新节点的引用

* 其他二叉树： AVL树（一种自平衡二叉搜索树）
* 意为： 任意一个节点左右两侧的子树的高度之差最多为1，即这种树在添加或者移除节点时会尽量试着成为一棵完整的树
* 为啥这么做： 树可能出现 一边很深，但另一边很浅的情况，这种情况下的搜索会影响性能

### 图（Graph）
* 一种非线性的数据结构，是网络结构的抽象模型
* 图是一组由边连接的节点（或顶点），可表示任何二元关系。
* 图由一组顶点，一组边组成
* 由一条边连在一起的顶点称为相邻顶点
* 一个顶点的度表示其相邻顶点的数量
* 路径是顶点v1，v2。。。vk的一个连续序列，其中vi和vi+1是相邻的
* 简单路径： 要求路径中不包含重复的顶点
* 若图中不存在环，则称该图是无环的
* 若图中任意两点都存在路径，则称该图是连通的。
* 图分为有向图和无向图（指边是否有方向）
* 若图中任意两点都双向存在路径，则称该图是强连通的
* 图可以是加权/未加权的，加权图的边是有权重的

* 图的表示： 
* 邻接矩阵： 用二维数组表示每两个节点之间是否连通（相对比较浪费空间，而且不太灵活）
* 邻接表： 列出每个节点相邻的节点
* 关联矩阵： 通常用于边比节点多的情况。该矩阵中，如果顶点v是边e的入射点，则array[v][e] === 1为true

* 图的实现
* 使用数组来存储节点的名字
* 使用字典来存储邻接表。（字典key为节点名，value为数组）
* 实现一个添加节点的方法： 名字数组添加节点名，对应字典里添加一个空数组
* 实现一个添加边的方法： 若添加的边两端的点为v和w，则字典中找出对应v点的数组，push w点进去；然后找出w点，将v点给push进去

##### 图的遍历
* 广度优先（BFS： Breadth First Search）
* 深度优先（DFS: Depth First Search）
* 图遍历可以用来寻找特定的顶点或者寻找两点之间的路径，检查图是否连通，检查图是否含有环

* 图遍历算法的思想
* 必须追踪每个第一次访问的节点，并且追踪有哪些节点还没有被完全探索，对于BFS和DFS，都需要指明第一个被访问的顶点
* 完全探索一个节点，即要求该顶点的所有边都被查看过
* 对于每一条边的连接的未访问过的顶点，将其标注为被发现的，并将其加入待访问顶点列表中
* 为保证算法效率，每个顶点最多访问2次，连通图中每条边和顶点都会被访问到
* BFS和DFS在算法上是基本相同的，只不过待访问列表的数据结构是不一样的，BFS使用队列来存储，而DFS则是使用栈来存储。这也导致了BFS会逐层访问一个图的顶点（按照距离最近的优先访问），而DFS则是沿着路径一直下探，直到最后一个顶点，然后原路返回并探索下一条路径

* BFS的执行顺序
1、创建一个队列Q
2、将v标注为被发现，并列入队列Q中
3、若Q非空，则：
a、将u从Q中取出
b、将u标注为已发现
c、将u所有未访问的邻点列入队列Q中
d、将u标注为已探索

* 使用BFS探索最短路径
* 对于给定顶点v，BFS会访问所有与其距离为1的顶点，接着是距离为2的顶点，以此类推
* 需要修改原先的方法来返回以下信息
1、从v到u的距离d[u]
2、前溯点pred[u] 用来推导从v到其他顶点u的最短距离
需要一个数组来表示距离，一个数组来表示前溯点

* 在获得上面两个数组后，观察第一个数组可以知道v到某个点的距离
* 观察第二个数组，可以知道v到某个点之间到路径
* 实际上，就是： 比如遍历到E，找出E在前溯数组中到值，比如是B，即B是E的前溯点。接着找出B的前溯点，发现是A，而A没有前溯点，即A是开始的顶点，结束。即可打印出A-B-E的路径为最短路径。（存在多个路径的话，就判断距离？）

* 其他最短路径算法：
* 若需要计算加权图的话，BFS就不适用了
* 可以使用Dijksra's算法——单源最短路径
* Bellman-Ford算法——边权值为负的单源最短路径
* A*搜索算法——求仅一对顶点的最短路径（经验法）
* Floyd-Warshall算法——求所有顶点之间的最短路径


##### DFS
* 不需要源顶点，若图中顶点v未访问，则访问v
* 要访问顶点v，则有以下步骤
1、标注v为被发现的
2、对于v的所有未访问邻点w
a、访问顶点w
3、标注v为已探索
* DFS的步骤是递归的，即意味着DFS使用栈存储函数的调用（由递归调用所创建的栈）

* 探索DFS
* 希望DFS去遍历图G的所有节点，构建“森林”（有根树的集合）以及一组源顶点（根），并输出两个数组：
发现时间和探索完成时间
* 1 <= d[u] <= d[f] <= 2|V|
（ 发现时间， 探索时间）
* 每访问一个节点时，时间会加1

* 拓扑排序： 有向无环图（DAG）
* 编排一些任务或者步骤，可以用拓扑排序来表示；另外，拓扑排序只能应用于DAG
* 拓扑排序会根据算法的不同而改变


### 排序算法
##### 冒泡排序
* 冒泡排序： 比较任何两个相邻的项，若第一个项比第二个大，则交换它们。元素项向上移动至正确的顺序。因像是气泡升至表面，得名冒泡排序
* 实现： 双层嵌套的for循环，若前面的项大于后面的项array[j] > array[j+1] 就交换
* 第一层for循环： 0到整个数组长度
* 第二层for循环： 0到第一层循环时的i
* 冒泡排序的改进： 在冒泡排序中，内循环实际上会重复跑外循环已经跑过的次数，这部分可以直接跳过。即内循环减去外循环已经跑过的次数
* 外层：  i < length  j< length -1 < i

##### 选择排序
* 一种原址比较算法： 找到数据结构中最小值排到第一位，接着找到次位最小值排到第二位，以此类推
* 时间复杂程度同冒泡排序

##### 插入排序
* 默认第一位已排序，作循环。循环长度为length-1次运算。在循环中中，若array[i]比前面的值小时，就交换位置。即array[i]会和array[i-1],array[i-2], ..., array[0] 依次作比较，直到该值前面的值比它小
* 在小型数组中 性能比选择/冒泡排序好

##### 归并排序
* 一种分治算法，其思想是将原始数组切分成较小的数组，直到每个小数组只有一个位置；接着将小数组归并称较大的数组，直到最后只有一个排序完毕的数组。
* 由于使用了分治法，所以归并排序是递归的
* 与前面类似，要实现一个递归函数需要实现一个实际被执行的辅助函数
* 利用递归和执行的顺序，先全部拆细分了再逐层合并

##### 快速排序
* 最常用的排序算法，复杂度是Olog(nlogn)，性能比其他的Olog(nlogn)要好
* 同样使用分治的方法，将数组分割开
* 步骤：
1、从数组中间选取一个主元
2、创建两个指针（分别在最左边和最右边），移动指针（左指针往右，右指针往左）移动时，若左边找到一个比主元大的项，且右边指针也找到一个比主元小的项，则交换指针所在的项，重复此过程，直到左指针超过右指针（位置）
3、重复2步骤，直到整个数组排序完毕
* 另： 如果左边或者右边没有找到比主元大/小的值，则会在主元处停留，若另一边有合适的值则会进行交换；然后不会停下来，直到两个指针交错后左指针大于右指针


### 搜索算法
* 之前的BST的search方法 和链表的indexOf方法都是搜索算法
##### 顺序搜索
* 也称为线性搜索。也就是将每一个数据结构中的元素和目标值进行比对，是最低效的一种算法。（即最简单的遍历）

##### 二分搜索
* 这个算法要求数据结构已排序
1、 选择数组的中间值
2、若选中值为目标值，则算法完成（也就是找到了）
3、若目标值比选中值大，则返回1，选中左边部分的数组的中间值进行比对
4、若目标值比选中值小，则返回1，选中左边部分的数组的中间值进行比对

* 实际上BST中的搜索就是这个算法的应用（只不过是针对BST这种数据结构的）

### 算法相关的补充知识
##### 递归
* 递归：是一种解决问题的方法，也就是先解决问题的各个小部分，直到解决最初的大问题
* 能够直接或间接调用自身的函数，叫做递归函数
* 递归函数需要一个停止边界（边界条件）来防止其无限递归调用造成栈溢出错误（Stack Overflow Error）
* ES6中的尾递归调用： 若函数内最后一个操作是调用函数，则会通过“跳转指令”（jump）而不是“子程序调用”（subroutine call）来控制

##### 斐波那契数列
* // 实现

##### 动态规划 （Dynamic Programming 简称DP）
* 一种将复杂问题分解成更小的子问题来解决的优先技术（之前的DFS也是其中的一种）
* DP和分治（归并排序，快速排序那种）是不同的方法
* 分治是将问题分解成相互独立的子问题，然后组合它们的解；而DP则是将问题分解成相互依赖的问题
* DP解决问题的三个步骤
1、定义子问题
2、实现要反复执行而解决子问题的部分（参考递归的步骤）
3、识别并求解出边界条件
* 能用DP解决的一些著名问题：
1、背包问题： 给出一组项目，各有值和容量的属性，目标是找出总值最大的组合。有个限制就是总容量要小于背包容量
2、最长公共子序列： 找出一组序列的最长公共子序列（可由另一序列删除元素但不改变余下元素的顺序而得到）
3、矩阵链相乘： 给出一系列矩阵，目标是找到这些矩阵相乘的最高效办法（计算数量尽可能少）
4、硬币找零： 给出面额d1,d2,...,dn的一定数量的硬币，找出有多少种找零方案
5、图的全源最短路径： 对所有顶点对(u,v)，找出从顶点u到顶点v的最短路径

##### 贪心算法
* 遵循一种近似解决问题的技术。期盼通过每个阶段的局部最优选择（当前最好的解），从而达到全局最优（全局最优解）。它不像DP，DP更适合计算更大的格局

##### 大O表示法
* 分析算法时，常见以下几类函数
O(1) 常数的
O(log(n))
O(C(log(n)))
O(n)
O(n2)
O(nc)
O(cn)
算了，直接用表吧

* 一般衡量算法的效率，通常用资源去计算（比如CPU占用、内存占用、硬盘占用、网络占用等）
* 大O表示法一般考虑CPU占用

例如
```JavaSCript
const increment = num => ++num
```
假设运行上面的函数，执行时间为X。若使用不同的参数运行一次，其执行时间也依旧为X，与传入的参数无关。也就是函数无论传入什么参数，运行时间是一样的。故上述函数的复杂度为O(1)，常数级别的

再来一个例子
```JavaSCript
const seqSearch = (array, item) => {
    for (let i = 0; i < array.length; i++) {
        if (item === array[i]) {
            return i
        }
        return -1
    }
}
// 假设这里传入的array是一个元素等于下标的数组，它的长度很长，比item要大
```
seqSearch这个函数的执行次数取决于参数item。即传1000作为item给这个函数，for循环就会跑1000次。若传入不存在的值，那么执行的次数就和数组的大小一样（这种是最坏情况）

那这种的复杂度就是O(n)，n为数组的大小，线性级别的

最后再来个例子： 冒泡排序

因为使用了双层for嵌套，执行的次数就是n乘以n，也就是O(n2)了
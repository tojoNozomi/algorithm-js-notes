# 算法与数据结构学习（JavaScript）

## 基础数据结构

### 栈 （Stack）

[栈的代码实现](./src/stack/index.js)

* 栈是一种遵循“后进先出（LIFO Last In First Out）”的序列，即最后入栈的元素会最先被取出来
* 栈的大小（size） 指的是数组含有的元素的数量（数组的长度）
* 栈的实现以及相关的方法

有种经典的算法——汉诺塔的移动，在该算法中，用来放圆盘的柱子就是可以看作栈

栈的适用场景： 

* 逆序输出： 反转字符串、数字等

* 语法检查： 比如<> () {} [] 这些都是成对出现的（排除大于号小于号的情况），遇到括号前半部分，就是进栈信号，遇到后半部分，就对比与栈顶元素是否匹配，匹配的话就出栈，否则就是匹配错误。常见于编译原理中的括号匹配问题

* 数制转换： 将十进制的数字转换成2到9之间的任意进制的树

另附：

汉诺塔的移动原理：
需要先把所有1到N-1的圆盘拿到一个柱子上，才能移动N圆盘到目标柱子上。这样递归操作，当只有一个的时候就可以直接移动以结束操作。

```javascript
const hanoi = (n, a, b, c) => {
    // 这里参数n是指需要移动多少个圆盘
    // 参数a的位置指需要移出的柱子
    // 参数b的位置指不用动
    // 参数c的位置指要被移入的柱子
    if (n === 1) {
        move(a, c)
        return
    }
    hanoi(n-1, a, c, b)
    move(a, c)
    hanoi(n-1, b, a, c)
}
const move = (a, c) => console.log(a + '->' + c)
hanoi(3, 'A', 'B', 'C')
```



***

### 队列 （Queue）

[队列的代码实现](./src/queue/index.js)

* 队列是一种遵循“先进先出（FIFO First In First Out）”原则的序列，先进入队列的元素会被先取出来
* 除了出入顺序不一样之外，其他的都和栈一样

##### 队列的实现

实现方式： 数组、链表
数组实现： 顺序队列、循环队列（head和tail的下标存起来？）

用栈实现队列：

```
使用两个栈，当所有元素对栈1入栈完毕后，将所有栈1的元素推出，并入到栈2；需要取用元素的时候就从栈2推出。（出栈顺序的反转）
```

用队列实现栈：

```
使用两个队列。当所有元素进入队列1完毕后，需要取用一个元素时，将队列1除了最后一个元素之外，全部出列并进入到队列2；当队列1清空后队列2的所有元素再次进入到队列1中（需要注意新入列时的时机）
（或者不做回转，留一个空的队列，入列的元素进入到有元素的队列中。）
```




##### 如果考虑优先级呢

[优先队列的代码实现](./src/queue/PriorityQueue.js)

* 实际上在生活中的队列不止这么简单，比如附带优先级的情况下

* 队列是这样作优先级判断的：在进入队列的时候比较优先级，然后插入到队列中的位置；或者是在出队列的时候，在队列中按照优先级选取
* 而实际上，从结果来看的话，两种优先队列在最终表现上基本是一致的，这里选取进入队列时进行优先级比较，出列时使用默认的出列方法

##### 另外一种队列的变形

循环队列： 元素出队列之后，再次进入到队尾 (待补充代码)

##### 队列的适用场景

* 缓冲器，或者用作解耦（模块之间使用消息队列来进行通信）。

* 秒杀队列： 对于瞬间过多的请求，可以先对所有请求按照时间顺序进行入队操作，存储到队列中，然后通过通过出列，按顺序来处理这些请求。
  （这是一种异步处理。同步是指在一个调用执行完成之后，等待调用结束返回；而异步则不会立即返回结果，返回时间是不可预测的，只有在另一端完成之后才会有结果，返回会通过另外的形式进行）

* 生产者和消费者模式：

  一种经典的设计模式。这个模式就像有一个传送带，生产者在一头将生产的产物放上去，消费者则从另一头将产物拿下来。实现的话，使用一个队列，若干个生产者同时向队列添加元素，而消费者则从队列中获取元素。



***

### 链表 （Linked list）

[链表的代码实现](./src/LinkedList/index.js)

* 背景： 因为很多时候数组的大小是固定的（比如C++这些语言），而且从数组起点和中间插入或者移除的成本会比较高。
* 于是乎就有了链表这种数据结构，与数组不同的是，链表中的元素并不是连续的，每个元素之间都由一个存储元素本身的节点和一个指向下一个元素的引用（也称指针，或者链接）组成
* 好处： 和数组一样是能存储有序的元素集合，不过添加或移动元素时不需要移动其他元素。另外需要访问一个元素时得从头开始遍历列表直到找到所需要的元素
* 链表的特点：

  1. 物理空间不连续，空间开销大
  2. 运行时可以动态添加
  3. 查找元素需要顺序查找
  4. 操作略显繁琐复杂


##### 其他种类的链表
* 双向链表： 在单向链表的基础上，即节点除了存储元素本身和下一个元素的引用之外，还存储着上一个元素的引用
* 循环链表： 链表的最后一个节点的下一个元素的引用指向第一个节点

##### 链表的适用场景：

单向链表、双向链表

```
优先使用双向链表，因为在遍历的时候可以选择从头或者尾开始遍历
消息缓冲也可以使用链表（方便对中间的消息进行操作）
```

栈可以使用链表实现（因为在头部删除或者添加的时间复杂度都是O(1)）

如何反转链表：

```
1. 遍历链表，使用头部插入（像循环队列那样）
2. 链表指针反转：将上一次遍历中的节点设置为next，并将存储上一次遍历的节点的指针指向当前的节点（for循环设置，需要额外的空间）
```

使用数组模拟，也就是静态链表：
可以使用对象来存储，也可以用两个数组分别保存当前节点和next指针；双向链表则需要3个数组
标记： 需要头指针标记、未指针标记以及未使用链表头指针标记

未使用链表也叫备用链表，用于串联没有被使用的数组元素。为接下来在链表中插入的操作使用。删除了的元素则要及时加入到备用链表的头部

静态链表的特点：

```
1. 空间需要连续申请，而且空间有限
2. 查找元素需要遍历
3. 操作更复杂
```



***

### 集合 （Set） 

[集合的代码实现](./src/LinkedList/index.js)

* 集合是无序且唯一的元素组成的（有限集合，数学上的概念）
* 集合是数组的一种拓展，没有大小限制，可以存放很多数据
  可变长度的列表（可以看作动态数组）
* 空集： 没有元素的集合 
* 一些集合的操作： 并集、交集、差集、子集

***

### 字典 （Dictionary）

[字典的代码实现](./src/Dictionary/index.js)

* 字典是一种以键值对[key, value]的形式存储数据的数据结构
* 与集合类似，集合是[value, value]的形式存储的，字典是[key, value]，字典也称作映射
* 例子： 实际意义上的字典、电话簿

***

### 散列表（Hash Table）

[散列表的代码实现](./src/HashTable/index.js)

散列表是基于字典表的一种散列实现，其作用是尽可能快地在数据结构中找到目标值

数据结构中，table 可以看作是一个length无限长的数组（JS的特性让定义这个很简单，当然在其他语言中需要定义数组的长度，一般根据可能的数据量设计散列表的大小，一般比数据总数大一些）

而散列表中比较重要的一点就是散列函数，用于键名到hash（散列值）的映射。最常见的一种散列函数“lose lose”： 简单地将键名中的每个字母的ASCII码相加。

在“lose lose”算法中，为了能够获得比较小的数，可以将相加的结果与任意一个数字作取模运算（mod， %）

因为直接通过键名到key（hash值）的映射，可以实现快速取值【参考后面的搜索算法】

哈希函数的一些实现

>* 直接寻址法：取关键字或关键字的某个线性函数值为散列地址
>* 数字分析法： 通过对数据分析，发现数据中冲突比较少的部分，并构造散列地址。例如学号，同一届的学生前面部分差别不大，可以用后面的部分来构造散列地址
>* 平方取中法：无法确定关键字哪几位的分布比较均匀时，可以先求出关键字的平方值、然后按需取平方值的中间几位作为散列地址。这是因为：计算后中间几位和关键字中每一位都相关，所以不同的关键字会以较高概率产生不同的散列地址
>* 取随机数法： 用一个随机函数，取出关键字的随机值作为散列地址，这种适合用于关键字长度不同的场合
>
>* 除留取余法： 取一个比散列表长度小一些的数m，关键字除以这个数后的余数作为散列值。 这个数字的选择比较重要，一般取素数或者直接用散列表长度n（也就是对素数取模 %）



哈希函数的选择一般需要考虑这些因素：

* 关键字的长度
* 哈希表的大小
* 关键字的分布情况
* 记录的查找频率

散列表的两种用法：

* 当key和value相同时，这种数据结构叫 Set（集合）
* 当key和value不同时，则叫Map（键值对集合）

特点： 访问快；需要额外空间；无序；可能会产生碰撞

适用场景： 

1. 缓存：比如需要高频次访问时就直接放在内存里
   或者需要联合查询的时候，可以先将部分数据取出来，再用这部分数据关联查找数据库的数据，可以降低数据库io占用

2. 快速查找： （不是指排序）快速取到值，而不用像数组那样遍历
   比如ip黑名单

散列表性能分析：

* 如果没有碰撞，那时间复杂度就是O(1)
* 如果使用链表法的话，那就是O(L)，L为链表长度

避免碰撞，当散列表大小不够的时候，可以扩容：
“扩充因子”（载荷因子），这是一个百分比，意思是容纳的数据达到这个值的时候性能就不好了。当达到扩容的阈值的时候，新的散列表的长度会是原来的2倍（一般）

Java中默认为0.75

#### 散列集合
* 由一个集合构成，但是插入、移除或者取出的时候，使用散列函数，只存储唯一的不重复的值
* 与散列表不同的是，只插入值而没有键

#### 解决冲突
实际上在使用的时候，会遇到刚好两个键名映射出来的hash值是一样的，这种情况下需要用一些方法来避免冲突

方法1: 分离链接（也叫链地址法）

 (因为只是简单地将链表和散列表结合起来，就先不实现了)

```
也就是在散列表的结构中，使用链表来存储键值，不过相比普通的散列表需要更多的空间来存储。

修改put方法： 先判断目标hash是否已经由链表存在，有的话就直接在链表进行add操作，没有的话就创建一个链表再add进去

修改add方法： 判断是否为空，空则返回undefined；非空，则遍历链表，比对键名并返回结果
```
方法2: 线性探查

[线性探查的代码实现](./src/HashTable/LinearProbingHashTable.js)

```
当向相同的位置插入一个新元素时，若索引为index的地方（hash值为index）已经被占用了，则尝试插入index+1位置，若也被占用了，则接着尝试index+2，以此类推

修改put方法： 若被占用时，则使用while条件判断，一直遍历下去

修改get方法： 和put类似，先hash计算后在指定位置上：
1. 检查是否存在元素，若无则返回undefined
2. 若存在元素，则判断键名是否相等；若不相等的话，则hash值+1，再判断是否存在或者是否键名相等
3. 返回键名相等的元素

修改remove方法： 与get类似，只不过在键名相等时的操作从返回变成设置为undefined（还要返回操作是否成功）
```

* 更好的散列函数djb2散列函数（比较受推荐的一种算法）

方法3:  再哈希法

在产生冲突之后，使用关键字的其他部分继续进行计算，如果还是有就再换另外一部分继续计算。缺点就是浪费时间

方法4: 建立一个公共溢出区，用来存储冲突的地址

***

### 树（Tree）
* 树是一种非顺序的数据结构。对于存储需要快熟查找的数据非常有用。其定义： 树是由n(N >= 1)个有限的节点组成的一种具有层次关系的集合。（因为长的像倒过来的树，所以被称为树）

* 常见例子： 家族谱、公司的组织架构图

  

  一个树结构，包含着一系列存在父子关系的节点，每个节点都有父节点（根节点除外）和0到多个子节点的引用

  

  常见术语

  ```
  * 至少有一个子节点的节点被称为内部节点
  
  * 没有子节点的节点则被称为外部节点或叶子节点
  
  * 节点可以有祖先和后代
  
  * 子树： 由当前节点以及其后代组成的树
  
  * 深度： 取决于节点的祖先节点的数量（直系）,即从根节点开始（起始深度为1）自顶向下逐层累加
  
  * 高度： 从叶子节点开始（起始高度为1）自底向上逐层累加
  
  * 森林： 由m棵不相交的树组成的集合
  
  * 节点的度： 一个节点含有的子树的个数。
  ```

  

  树的种类： 二叉树、平衡二叉树、B树、B+树、哈夫曼树、B-树、B*树、红黑树、trie树等

  

  满二叉树： 每个节点（除了叶子节点）都有左右两棵子树

  

  完全二叉树： 所有叶子节点都出现在第k层，而且从1到k-1层必须达到最大节点数。第k层可以不是满的，但是第k层的所有节点必须集中在最左边

  

  二叉树还可以使用数组实现

  

  ##### 平衡二叉树

  如果一个二叉树的每个节点只有左边子树或者只有右边子树的话，那就和链表一样了，会丢失BST原有的性能。平衡二叉树也叫AVL树
  特点： 查找算法的平均情况和最坏情况都是O(logn)，其删除和插入操作也是O(logn)，删除或者插入后高度能保持相对平衡

  平衡二叉树或者一棵空树，或者满足这两个条件的二叉查找树： 其左右子树都是平衡二叉树，而且左右子树的高度之差的绝对值不大于1

  即左右子树的高度差只有-1、0、1三种可能

  平衡因子： Balanced Factor 每个节点都有一个平衡因子，这个节点的平衡因子就是左子树的高度减去右子树的高度

  RR型失衡： 新节点加到了失衡节点的右子树的右子树上。 失衡后需要作旋转（左逆时针的旋转）

  RL（右子树的左子树失衡）、LL（左子树的左子树失衡， 右顺时针旋转）、LR（左子树的右子树失衡）

  

##### 二叉搜索树（BST： Binary Search Tree）
* 特性：二叉树的子节点最多只有两个（左侧节点和右侧节点）。
* 二叉搜索树： 只允许左侧节点的值小于父节点，而右侧节点的值要大于父节点
* 在代码实现中通过指针来表示节点之间的关系（术语中称为边），而节点本身在树相关的术语中称为键 Key
* insert方法的实现：
1、创建Node类的实例 2、判断根节点是否为空，是则root被赋值（用刚创建的节点），结束
3、若根节点存在，则判断当前节点和根节点的大小，若小的话往左边遍历，若大的话则往右边遍历
4、在上述情况中，如果当前节点的左/右节点指针为空时，恰好新节点比当前节点小/大时，则直接插入

##### BST的三种遍历
* 中序遍历： 以从最小到最大的顺序访问所有节点（先访问左节点，再访问自身，最后访问右节点）
* 应用：对树中的元素进行排序
* 利用递归的先后执行顺序的区别来实现（同步代码）
* 先序遍历： 优先于后代访问的顺序（先访问本节点，再访问左节点，最后访问右节点）
* 后序遍历： 优先访问后代节点（先访问左节点，再访问右节点，最后访问自身）
* 先中后 三种遍历顺序实际上就是访问本节点的先后顺序（无论怎么排左节点都是优先于右节点访问的）
* BST中的值： 最小值（一直访问右节点，直到所访问的节点是叶子节点时的值） 
最大值（一直访问右节点，直到所访问的节点是叶子节点时的值）
* 特定值（的搜索）： 判断目标值和当前节点的大小，如果小于当前节点的键，则往右；如果大于当前节点的键，则往左。迭代下去，直到目标值和当前节点的键相等，返回true。若不出现相等的情况则返回false
* 移除节点： 基于search的方法，在找到目标值之后，若该节点是叶子节点，则另node为null；若只有一个子节点的情况下，则令子节点替换该节点；若有两个子节点，则先找出右边子树的最小节点，来替换目标节点，并从原位置移除，最后向父节点返回更新节点的引用
* 其他二叉树： AVL树（一种自平衡二叉搜索树）
* 意为： 任意一个节点左右两侧的子树的高度之差最多为1，即这种树在添加或者移除节点时会尽量试着成为一棵完整的树
* 为啥这么做： 树可能出现 一边很深，但另一边很浅的情况，这种情况下的搜索会影响性能



##### B树

B-树 B-Tree 实际上并不是减号，这里是横杠，就读作B树

当数据量非常大的时候，内存不够放，那么需要放到硬盘里。于是就有B-树了

虽然平衡二叉树性能很好，但是面对数据量足够大的情况，搜索还是很费时的。

m-路查找树（m-Way Search Tree）： 根节点最多包含m棵子树；每个节点有n个数据元素

***

### 图（Graph）
* 一种非线性的数据结构，是网络结构的抽象模型
* 图是一组由边连接的节点（或顶点），可表示任何二元关系。
* 图由一组顶点，一组边组成
* 由一条边连在一起的顶点称为相邻顶点
* 一个顶点的度表示其相邻顶点的数量
* 路径是顶点v1，v2。。。vk的一个连续序列，其中vi和vi+1是相邻的
* 简单路径： 要求路径中不包含重复的顶点
* 若图中不存在环，则称该图是无环的
* 若图中任意两点都存在路径，则称该图是连通的。
* 图分为有向图和无向图（指边是否有方向）
* 若图中任意两点都双向存在路径，则称该图是强连通的
* 图可以是加权/未加权的，加权图的边是有权重的

* 图的表示： 
* 邻接矩阵： 用二维数组表示每两个节点之间是否连通（相对比较浪费空间，而且不太灵活）
* 邻接表： 列出每个节点相邻的节点
* 关联矩阵： 通常用于边比节点多的情况。该矩阵中，如果顶点v是边e的入射点，则array[v][e] === 1为true

* 图的实现
* 使用数组来存储节点的名字
* 使用字典来存储邻接表。（字典key为节点名，value为数组）
* 实现一个添加节点的方法： 名字数组添加节点名，对应字典里添加一个空数组
* 实现一个添加边的方法： 若添加的边两端的点为v和w，则字典中找出对应v点的数组，push w点进去；然后找出w点，将v点给push进去

##### 图的遍历
* 广度优先（BFS： Breadth First Search）
* 深度优先（DFS: Depth First Search）
* 图遍历可以用来寻找特定的顶点或者寻找两点之间的路径，检查图是否连通，检查图是否含有环

* 图遍历算法的思想
* 必须追踪每个第一次访问的节点，并且追踪有哪些节点还没有被完全探索，对于BFS和DFS，都需要指明第一个被访问的顶点
* 完全探索一个节点，即要求该顶点的所有边都被查看过
* 对于每一条边的连接的未访问过的顶点，将其标注为被发现的，并将其加入待访问顶点列表中
* 为保证算法效率，每个顶点最多访问2次，连通图中每条边和顶点都会被访问到
* BFS和DFS在算法上是基本相同的，只不过待访问列表的数据结构是不一样的，BFS使用队列来存储，而DFS则是使用栈来存储。这也导致了BFS会逐层访问一个图的顶点（按照距离最近的优先访问），而DFS则是沿着路径一直下探，直到最后一个顶点，然后原路返回并探索下一条路径

* BFS的执行顺序
1、创建一个队列Q
2、将v标注为被发现，并列入队列Q中
3、若Q非空，则：
a、将u从Q中取出
b、将u标注为已发现
c、将u所有未访问的邻点列入队列Q中
d、将u标注为已探索

* 使用BFS探索最短路径
* 对于给定顶点v，BFS会访问所有与其距离为1的顶点，接着是距离为2的顶点，以此类推
* 需要修改原先的方法来返回以下信息
1、从v到u的距离d[u]
2、前溯点pred[u] 用来推导从v到其他顶点u的最短距离
需要一个数组来表示距离，一个数组来表示前溯点

* 在获得上面两个数组后，观察第一个数组可以知道v到某个点的距离
* 观察第二个数组，可以知道v到某个点之间到路径
* 实际上，就是： 比如遍历到E，找出E在前溯数组中到值，比如是B，即B是E的前溯点。接着找出B的前溯点，发现是A，而A没有前溯点，即A是开始的顶点，结束。即可打印出A-B-E的路径为最短路径。（存在多个路径的话，就判断距离？）

* 其他最短路径算法：
* 若需要计算加权图的话，BFS就不适用了
* 可以使用Dijksra's算法——单源最短路径
* Bellman-Ford算法——边权值为负的单源最短路径
* A*搜索算法——求仅一对顶点的最短路径（经验法）
* Floyd-Warshall算法——求所有顶点之间的最短路径


##### DFS
* 不需要源顶点，若图中顶点v未访问，则访问v
* 要访问顶点v，则有以下步骤
1、标注v为被发现的
2、对于v的所有未访问邻点w
a、访问顶点w
3、标注v为已探索
* DFS的步骤是递归的，即意味着DFS使用栈存储函数的调用（由递归调用所创建的栈）

* 探索DFS
* 希望DFS去遍历图G的所有节点，构建“森林”（有根树的集合）以及一组源顶点（根），并输出两个数组：
发现时间和探索完成时间
* 1 <= d[u] <= d[f] <= 2|V|
（ 发现时间， 探索时间）
* 每访问一个节点时，时间会加1

* 拓扑排序： 有向无环图（DAG）
* 编排一些任务或者步骤，可以用拓扑排序来表示；另外，拓扑排序只能应用于DAG
* 拓扑排序会根据算法的不同而改变

***

### 排序算法
衡量排序算法的几个标准：
时间复杂度
空间复杂度
稳定性： 同样的输入、多次运算后结果一致
（在排序算法中，经过排序后，元素之间的相对次序保持不变，则称算法是稳定的）

算法稳定的好处： 有些结果可以接着用（在输入一致的情况下）。

选择排序算法的考虑因素：

```
1、待排序的数列长度
2、记录本身的数据量（往往会根据一些记录中的部分内容其排序，有时候需要考虑其他部分的数据量的大小）
3、待排序的数列元素结构以及分布情况（虽然桶排序很快，但是如果分布区间过大，就不适合使用桶排序）
4、对算法稳定性对要求（适合一些重复输入多的场合）
```

##### 桶排序

 也叫箱排序。是所有算法中最快最简单的排序算法

和散列表很相似。内部排序时可以对其他准确高效的算法进行。

实现上，对数值进行判断装入哪个桶，然后在对应桶上（使用数组或者链表都行）加入该数值

性能： 时间复杂度O(n+m)，n为待排序元素数量，m为桶的数量
空间复杂度： O(m)

适用场景： 数据跨度不太大的情况下可以用



##### 冒泡排序

概念：比较任何两个相邻的项，若第一个项比第二个大，则交换它们。元素项向上移动至正确的顺序。因像是气泡升至表面，得名冒泡排序

实现： 

```
1. 双层嵌套的for循环，若前面的项大于后面的项array[j] > array[j+1] 就交换
2. 第一层for循环： 0到整个数组长度
3. 第二层for循环： 0到第一层循环时的i
4. 冒泡排序的改进： 在冒泡排序中，内循环实际上会重复跑外循环已经跑过的次数，这部分可以直接跳过。即内循环减去外循环已经跑过的次数
5. 外层：  i < length  j< length -1 < i
```

时间复杂度O(n^2)

##### 选择排序
* 一种原址比较算法： 找到数据结构中最小值排到第一位，接着找到次位最小值排到第二位，以此类推
* 时间复杂程度同冒泡排序

特点和性能：

```
在待排序数组上直接进行排序和交换，使用常数级别的额外空间，也就是空间复杂度为： O(1)
时间复杂度上，因为有两层循环，时间复杂度为O(n^2)，不过比起冒泡算法还是相对节省计算时间的

这也是一种不稳定的排序算法
```

优化：
在循环的同时，进行最大值和最小值的查找，然后分别置于数组的起始和末尾的位置，节省一半的时间

适用场景： 不太常用

##### 插入排序
* 默认第一位已排序，作循环。循环长度为length-1次运算。在循环中中，若array[i]比前面的值小时，就交换位置。即array[i]会和array[i-1],array[i-2], ..., array[0] 依次作比较，直到该值前面的值比它小
* 在小型数组中 性能比选择/冒泡排序好

##### 归并排序
* 一种分治算法，其思想是将原始数组切分成较小的数组，直到每个小数组只有一个位置；接着将小数组归并称较大的数组，直到最后只有一个排序完毕的数组。
* 由于使用了分治法，所以归并排序是递归的
* 与前面类似，要实现一个递归函数需要实现一个实际被执行的辅助函数
* 利用递归和执行的顺序，先全部拆细分了再逐层合并

##### 快速排序
* 最常用的排序算法，复杂度是O(nlogn)，公认为是相同数量级到所有排序算法中，平均性能最好的

* 同样使用分治的方法，将数组分割开

  

  步骤：

  ```
  1、从数组中间选取一个主元
  2、创建两个指针（分别在最左边和最右边），移动指针（左指针往右，右指针往左）移动时，若左边找到一个比主元大的项，且右边指针也找到一个比主元小的项，则交换指针所在的项，重复此过程，直到左指针超过右指针（位置）
  3、重复2步骤，直到整个数组排序完毕
  
  另： 如果左边或者右边没有找到比主元大/小的值，则会在主元处停留，若另一边有合适的值则会进行交换；然后不会停下来，直到两个指针交错后左指针大于右指针
  ```

  最坏情况： O(n^2) 
  平均情况： O(nlogn)
  空间复杂度: O(logn) 最坏情况： O(n)

  适用场景： 非常常用的排序算法，性能上可能没有一些复杂算法做得好，但是学习成本低

  

  快排的优化：

  ```
  1、三者取中法：  在数组中间选取基准值，减少潜在移动的次数
  
  2、根据规模的大小改变算法： 因为在数据量比较小的情况下，快排的性能没有其他算法好，可以使用其他的算法。一般这个值可以使用： 5到25
  
  3、其他分区方案考虑： 选择的基准数可能有多个，这个时候可以考虑改变分区的方案，那就是分三个分区，除了小于基准数的区间，大于基准数的分区，还有一个等于基准数的分区。这样每次进行递归的时候可以跳过等于基准数的分区，减少无谓
  
  4、并行处理： 由于快排中每一段排序，对其他段的排序没有影响，可以使用多线程技术来提高效率。多用于数据量比较大的情况
  ```



##### 二分插入排序

使用二分法找出可以插入的位置并插入，同样是使用了分治思想

##### 希尔排序

直接插入排序的一种改进

如果插入排序在序列本身有序的时候，能够达到O(n)的时间复杂度（效率高了起来）。

希尔排序也叫插入排序算法，也叫缩小增量排序。

在插入排序的基础上，主要通过这两点来提高效率：

1. 插入排序在对近似有序的数列进行排序的时候排序性能比较好
2. 插入排序本身性能比较低，每次只能移动一位数据

原理：

```
将待排序的数列按照一定的增量分割成多个子数列，但是这个子序列不是连续的，而是通过前面提到的增量，按照一定相隔的增量进行分割的，然后对各个子数列进行插入排序；接着增量逐渐减小，然后依然对每部分进行插入排序，在减少到1后对整体使用插入排序处理

增量的减少，可以是每次是上一次的1/2 （不为整数时自动取整）
增量为1时 也就是普通的插入排序
```

希尔排序的特点和性能：

因为增量的序列不一定，时间复杂度也是不确定的

最好情况： 本身是有序的，复杂度为O(n)
一般认为希尔排序的时间复杂度为O(n^1.3)
空间复杂度O(1)

另： 因为希尔排序会进行分组排序，所以同样值的元素，其相对位置可能会发生变化，这是因为，同样值的元素若不在一个组中，可能后面的元素会被移动到前面。所以这是不稳定的算法

使用场景： 不太常用的排序


### 搜索算法


之前的BST的search方法 和链表的indexOf方法都是搜索算法

##### 顺序搜索
也称为线性搜索。也就是将每一个数据结构中的元素和目标值进行比对，是最低效的一种算法。（即最简单的遍历）

顺序查找的特点和性能：
优化上可以使用多线程技术，对序列进行分割查找
ASL（Average Search Length 平均查找长度）—— 需要和目标key进行比较的期望次数，称为平均查找长度

查找成功时的ASL的计算公式为： ASL = Pi * Ci，其中Pi是查找表中第i个元素的概率，Ci为找到第i个元素时已经比较过的次数
比如顺序查找能够找到的情况下，ASL = 1/(n*(1+2+3+...+n))
也就是 (1+n)/2，这里假设每个元素的查找概率相同。最坏情况下就是没有找到，近似比较了n+2次（优化过后是n+2次，而普通的顺序查找则需要2n次）

顺序查找平均时间复杂度O(n)，空间复杂度O(1)

适用场景：
元素不多的情况下可以使用，图个方便

##### 二分搜索
* 这个算法要求数据结构已排序
1、 选择数组的中间值
2、若选中值为目标值，则算法完成（也就是找到了）
3、若目标值比选中值大，则返回1，选中左边部分的数组的中间值进行比对
4、若目标值比选中值小，则返回1，选中左边部分的数组的中间值进行比对
* 实际上BST中的搜索就是这个算法的应用（只不过是针对BST这种数据结构的）

二分查找的优化：
为了能够更接近待查数字，使用计算来获得目标的大概位置，并从那里开始查找。这种优化后的算法叫作插值查找，对于数列比较大而且比较均匀的数列来说，性能会比较好。如果数列非常不均匀的话，效果没有二分查找好

二分查找的ASL为((n+1)log(n+1))/n-1 可以简化为logn （前面的log底数都为2）

最好情况一次找到，正常情况是O(logn)

适用场景：
要求数列是有序的。（所以使用之前要判断数列是否有序）
无序的话还需要先进行排序

在列表很长的情况下，而且能用数据库针对某个字段进行排序的话就很适合使用二分查找

如果是需要频繁插入删除的数列，则二分查找不一定适用



##### 二分插入排序
在二分查找的基础上（利用二分查找找到插入值应该插入的位置）
（得基于原本数列是有序的情况下）


行列递增的矩阵查找——二分查找的思维拓展

假设有个m行n列的矩阵，用二维数组表示，这里面数据每一行和每一列都是递增的，这种结构称为杨氏矩阵。在这种矩阵中的查找则称为杨氏矩阵查找，一般在杨氏矩阵中查找值为k的数，判断是否存在

解法1: 递归——全部扫一遍

解法2: 按照路径（方向）查找

第一行遍历查找有没有，没有的话就在目标值附近向下查找，然后再左右找，没有的话接着向下找

解法3: 分治法

先在第一个元素取对角线，往下查找是否存在，没有的话在目标值最接近的两个元素，划分出来的坐标系中的第一第三象限中查找；
然后在这两个区域接着找对角线，然后接着这么找下去
（对于数据量多的情况下很好用）

解法4: 定位查找法

使用方法2，但是从第一行的最右边开始查找，这样的话就不会出现向右查找的行为，相对较快



##### 搜索算法的一些扩展

杨氏矩阵的相关扩展： 

如果矩阵中有空的，填充矩阵会用 无限大 进行填充



分块查找：

经常进行增删操作的元素列表，不太适用二分查找。那么可以使用分块查找。这是结合二分法和顺序查找的一种方式。这里有索引表和分块的概念。

索引表是帮助分块查找的一个分块依据，实际上就是一个数组，用来存储每一块的最大存储值，也就是范围上限。而分块就是通过索引表把数据分成多少块

所以每当需要添加元素的时候，就先根据索引表，找出该元素应该在哪一块，然后直接将该数据加入到相应的块中，而这个块中无须有序。这也使得分块查找适合元素经常变动的情况

只需要索引表有序即可，当索引表比较大的时候，可以考虑对索引表使用二分查找，找到后对块进行顺序查找即可。虽然比二分查找要慢，但是比顺序查找不知道高到哪里去，最重要的是无须有序

虽然块内是无序的，但是块与块之间的元素是有序的，比如块1的任意一个元素都比块2的任意一个元素小



特点和性能：

有着顺序查找和二分查找的双重优势

分块算法比较复杂，需要根据元素等进行划分块，让块能够均匀而且不密集。过于稀疏则顺序查索引表耗时；而过于密集则无论删除还是插入都会密集调用二分查找。块数特别多的话则和二分查找没多少区别。

二分查找的ASL为log(n+1)-1，n为块数。而顺序查找的ASL为(n+1)/2。

尽量等分块的情况下，假设块数为a，块内元素数量为b，对总数据量为n的数据进行分块，则总的ASL为(b+1)/2 + log(a+1) - 1
这样就能解出a，b分别为多少了



适用场景：

虽然不会直接用到分块查找（用起来没有散列表好用），但是思想是可以借鉴的。
比如会根据具体业务量做分表；像大量日志需要保存的话，可以按日期分表，这样也方便查找

一般来讲，根据具体情况可以直接选择顺序查找或者二分查找，也可以使用散列表的形式获取数据。如果数据量少，直接用顺序查找比较简单方便，而且不易出错；若数据变化不太频繁，那就可以选择二分查找



搜索引擎：
概念： 指从大量的数据中根据关键字查找出相应的信息。搜索引擎之所以能够快速地根据关键字获取到结果，都要归功于索引。



倒排索引： Inverted Index
适使用关键字作为索引，比如标记出现了这些关键字的文档有哪些，然后索引会和文章id关联起来，搜索的时候就能直接返回了

进行文章搜索时，希望搜索内容能优先匹配标题，其次才是文章内容，也就是相关度。于是可以对这两种内容分别索引，然后根据相关度进行显示。这样建立的索引就是倒排索引

***

### 算法相关的补充知识
##### 递归
* 递归：是一种解决问题的方法，也就是先解决问题的各个小部分，直到解决最初的大问题
* 能够直接或间接调用自身的函数，叫做递归函数
* 递归函数需要一个停止边界（边界条件）来防止其无限递归调用造成栈溢出错误（Stack Overflow Error）
* ES6中的尾递归调用： 若函数内最后一个操作是调用函数，则会通过“跳转指令”（jump）而不是“子程序调用”（subroutine call）来控制

##### 斐波那契数列
* // 实现

##### 动态规划 （Dynamic Programming 简称DP）
* 一种将复杂问题分解成更小的子问题来解决的优先技术（之前的DFS也是其中的一种）
* DP和分治（归并排序，快速排序那种）是不同的方法
* 分治是将问题分解成相互独立的子问题，然后组合它们的解；而DP则是将问题分解成相互依赖的问题
* DP解决问题的三个步骤
1、定义子问题（一个问题可以被分解成多个子问题）
2、实现要反复执行而解决子问题的部分（参考递归的步骤）（该问题和子问题除了数据规模之外，求解思路一致）
3、识别并求解出边界条件（存在递归终止条件，即出口）
* 能用DP解决的一些著名问题：
1、背包问题： 给出一组项目，各有值和容量的属性，目标是找出总值最大的组合。有个限制就是总容量要小于背包容量
2、最长公共子序列： 找出一组序列的最长公共子序列（可由另一序列删除元素但不改变余下元素的顺序而得到）
3、矩阵链相乘： 给出一系列矩阵，目标是找到这些矩阵相乘的最高效办法（计算数量尽可能少）
4、硬币找零： 给出面额d1,d2,...,dn的一定数量的硬币，找出有多少种找零方案
5、图的全源最短路径： 对所有顶点对(u,v)，找出从顶点u到顶点v的最短路径

##### 贪心算法
* 遵循一种近似解决问题的技术。期盼通过每个阶段的局部最优选择（当前最好的解），从而达到全局最优（全局最优解）。它不像DP，DP更适合计算更大的格局

##### 大O表示法
* 分析算法时，常见以下几类函数
O(1) 常数的
O(log(n))
O(C(log(n)))
O(n)
O(n2)
O(nc)
O(cn)
算了，直接用表吧

* 一般衡量算法的效率，通常用资源去计算（比如CPU占用、内存占用、硬盘占用、网络占用等）
* 大O表示法一般考虑CPU占用

例如
```JavaSCript
const increment = num => ++num
```
假设运行上面的函数，执行时间为X。若使用不同的参数运行一次，其执行时间也依旧为X，与传入的参数无关。也就是函数无论传入什么参数，运行时间是一样的。故上述函数的复杂度为O(1)，常数级别的

再来一个例子
```JavaSCript
const seqSearch = (array, item) => {
    for (let i = 0; i < array.length; i++) {
        if (item === array[i]) {
            return i
        }
        return -1
    }
}
// 假设这里传入的array是一个元素等于下标的数组，它的长度很长，比item要大
```
seqSearch这个函数的执行次数取决于参数item。即传1000作为item给这个函数，for循环就会跑1000次。若传入不存在的值，那么执行的次数就和数组的大小一样（这种是最坏情况）

那这种的复杂度就是O(n)，n为数组的大小，线性级别的

最后再来个例子： 冒泡排序

因为使用了双层for嵌套，执行的次数就是n乘以n，也就是O(n2)了